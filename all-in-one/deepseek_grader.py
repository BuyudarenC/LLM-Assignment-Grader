#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡å‹ä½œä¸šæ‰¹æ”¹å™¨
æ”¯æŒDeepSeekã€OpenAIå…¼å®¹æ ¼å¼å’Œå…¶ä»–æ¨¡å‹è¿›è¡Œä½œä¸šæ‰¹æ”¹
"""

import os
import json
import time
import requests
from pathlib import Path
from datetime import datetime
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultiModelGrader:
    def __init__(self, api_config, model_name="unknown"):
        """
        åˆå§‹åŒ–å¤šæ¨¡å‹æ‰¹æ”¹å™¨
        
        Args:
            api_config: APIé…ç½®å­—å…¸
            model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        """
        self.api_config = api_config
        self.model_name = model_name
        self.prompt_template = ""
        
    def load_prompt(self, prompt_file="prompt.txt"):
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                self.prompt_template = f.read()
            logger.info(f"å·²åŠ è½½æç¤ºè¯æ¨¡æ¿: {prompt_file}")
        except FileNotFoundError:
            logger.error(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
            raise
        except Exception as e:
            logger.error(f"åŠ è½½æç¤ºè¯å¤±è´¥: {e}")
            raise
    
    def read_homework_content(self, homework_path):
        """è¯»å–å­¦ç”Ÿä½œä¸šå†…å®¹"""
        try:
            with open(homework_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return content
        except Exception as e:
            logger.error(f"è¯»å–ä½œä¸šæ–‡ä»¶å¤±è´¥ {homework_path}: {e}")
            return None
    
    def get_directory_tree(self, student_dir):
        """è·å–å­¦ç”Ÿç›®å½•ç»“æ„"""
        try:
            import subprocess
            result = subprocess.run(
                ['tree', student_dir, '/F'], 
                capture_output=True, 
                text=True, 
                encoding='utf-8'
            )
            return result.stdout if result.returncode == 0 else "ç›®å½•ç»“æ„è·å–å¤±è´¥"
        except Exception:
            # å¦‚æœtreeå‘½ä»¤ä¸å¯ç”¨ï¼Œä½¿ç”¨Pythonå®ç°ç®€å•çš„ç›®å½•ç»“æ„
            return self._simple_tree(student_dir)
    
    def _simple_tree(self, directory, prefix="", max_depth=3, current_depth=0):
        """ç®€å•çš„ç›®å½•æ ‘å®ç°"""
        if current_depth >= max_depth:
            return ""
        
        tree_str = ""
        try:
            items = sorted(Path(directory).iterdir())
            for i, item in enumerate(items):
                is_last = i == len(items) - 1
                current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                tree_str += f"{prefix}{current_prefix}{item.name}\n"
                
                if item.is_dir() and current_depth < max_depth - 1:
                    extension = "    " if is_last else "â”‚   "
                    tree_str += self._simple_tree(
                        item, prefix + extension, max_depth, current_depth + 1
                    )
        except PermissionError:
            tree_str += f"{prefix}[æƒé™ä¸è¶³]\n"
        
        return tree_str
    
    def get_git_log(self, student_dir):
        """è·å–Gitæäº¤æ—¥å¿—"""
        try:
            import subprocess
            result = subprocess.run(
                ['git', 'log', '--oneline', '-10'], 
                cwd=student_dir,
                capture_output=True, 
                text=True, 
                encoding='utf-8'
            )
            return result.stdout if result.returncode == 0 else "æ— Gitå†å²è®°å½•"
        except Exception:
            return "æ— æ³•è·å–Gitå†å²è®°å½•"
    
    def build_grading_prompt(self, homework_content, tree_output, git_log):
        """æ„å»ºæ‰¹æ”¹æç¤ºè¯"""
        prompt = self.prompt_template.replace("HOMEWORK", homework_content)
        return prompt
    
    def call_llm_api(self, prompt):
        """è°ƒç”¨LLM APIï¼ˆæ”¯æŒOpenAIå…¼å®¹æ ¼å¼ï¼‰"""
        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                "model": self.api_config["model"],
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä½œä¸šæ‰¹æ”¹åŠ©æ•™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.5,
                "max_tokens": 2000
            }
            
            # æ„å»ºè¯·æ±‚å¤´
            headers = {}
            for key, value in self.api_config["headers"].items():
                if "{key}" in value and self.api_config["key"]:
                    headers[key] = value.format(key=self.api_config["key"])
                elif "{key}" not in value:
                    headers[key] = value
                # å¦‚æœkeyä¸ºç©ºä¸”éœ€è¦keyï¼Œåˆ™è·³è¿‡è¿™ä¸ªheader
            
            # å¦‚æœæ²¡æœ‰keyæˆ–keyä¸ºç©ºï¼Œç§»é™¤Authorization headerï¼ˆé€‚ç”¨äºæœ¬åœ°éƒ¨ç½²ï¼‰
            if not self.api_config["key"] or self.api_config["key"] in ["", "sk-local-key-or-empty"]:
                headers.pop("Authorization", None)
            
            logger.debug(f"è°ƒç”¨ {self.model_name} API: {self.api_config['url']}")
            
            # å‘é€è¯·æ±‚
            response = requests.post(
                self.api_config["url"],
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    return result["choices"][0]["message"]["content"]
                else:
                    logger.error(f"{self.model_name} APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")
                    return None
            else:
                logger.error(f"{self.model_name} APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"{self.model_name} APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def parse_grading_result(self, llm_response):
        """è§£æLLMè¿”å›çš„æ‰¹æ”¹ç»“æœ"""
        try:
            # æ–¹æ³•1: ç›´æ¥æŸ¥æ‰¾JSONéƒ¨åˆ†
            start_idx = llm_response.find("{")
            end_idx = llm_response.rfind("}") + 1
            
            if start_idx != -1 and end_idx != 0:
                json_str = llm_response[start_idx:end_idx]
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError:
                    pass  # ç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•
            
            # æ–¹æ³•2: æŸ¥æ‰¾markdownä»£ç å—ä¸­çš„JSON
            import re
            
            # æŸ¥æ‰¾ ```json æˆ– ``` ä»£ç å—
            json_pattern = r'```(?:json)?\s*\n?(.*?)\n?```'
            matches = re.findall(json_pattern, llm_response, re.DOTALL | re.IGNORECASE)
            
            for match in matches:
                try:
                    # å°è¯•è§£ææ‰¾åˆ°çš„å†…å®¹
                    json_data = json.loads(match.strip())
                    return json_data
                except json.JSONDecodeError:
                    continue
            
            # æ–¹æ³•3: å°è¯•ä»æ•´ä¸ªå“åº”ä¸­æå–ç»“æ„åŒ–æ•°æ®
            # å¦‚æœå“åº”åŒ…å«markdownæ ¼å¼ï¼Œå°è¯•ä»ä¸­æå–å…³é”®ä¿¡æ¯
            lines = llm_response.split('\n')
            extracted_data = {}
            
            for line in lines:
                line = line.strip()
                # å¯»æ‰¾ç±»ä¼¼ "ç»“æ„å®Œæ•´æ€§": {"score": 13, "reason": "..."} çš„æ¨¡å¼
                if '"ç»“æ„å®Œæ•´æ€§"' in line or '"ä½œä¸šå†…å®¹å›ç­”"' in line or '"å‘½ä»¤æ‰§è¡Œä¸è¯´æ˜"' in line or '"å®éªŒè¿‡ç¨‹å¤ç°æ€§"' in line or '"æ ¼å¼è§„èŒƒä¸å¯è¯»æ€§"' in line or '"æ€»åˆ†"' in line:
                    try:
                        # å°è¯•ä»è¡Œä¸­æå–JSONç‰‡æ®µ
                        start = line.find('{')
                        if start != -1:
                            json_part = '{' + line[start+1:]
                            if json_part.endswith(','):
                                json_part = json_part[:-1]
                            test_data = json.loads(json_part)
                            # å¦‚æœè§£ææˆåŠŸï¼Œå°†å…¶åˆå¹¶åˆ°ç»“æœä¸­
                            extracted_data.update(test_data)
                    except:
                        continue
            
            if extracted_data:
                return extracted_data
            
            logger.error(f"æ— æ³•ä»{self.model_name}å“åº”ä¸­æå–JSONæ ¼å¼çš„è¯„åˆ†ç»“æœ")
            logger.error(f"åŸå§‹å“åº”: {llm_response[:500]}...")
            return None
                
        except Exception as e:
            logger.error(f"è§£ææ‰¹æ”¹ç»“æœæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            logger.error(f"åŸå§‹å“åº”: {llm_response[:200]}...")
            return None
    
    def grade_single_homework(self, student_name, homework_path, student_dir, max_retries=3):
        """æ‰¹æ”¹å•ä¸ªå­¦ç”Ÿçš„ä½œä¸šï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        logger.info(f"ğŸ” å¼€å§‹æ‰¹æ”¹å­¦ç”Ÿ: {student_name}")
        
        # è¯»å–ä½œä¸šå†…å®¹
        homework_content = self.read_homework_content(homework_path)
        if homework_content is None:
            logger.error(f"âŒ å­¦ç”Ÿ {student_name} ä½œä¸šæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè·³è¿‡æ‰¹æ”¹")
            return None
        
        # è·å–ç›®å½•ç»“æ„å’ŒGitæ—¥å¿—ï¼ˆè¿™äº›ä¸éœ€è¦é‡è¯•ï¼‰
        tree_output = self.get_directory_tree(student_dir)
        git_log = self.get_git_log(student_dir)
        
        # æ„å»ºæç¤ºè¯
        prompt = self.build_grading_prompt(homework_content, tree_output, git_log)
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ“ å°è¯•æ‰¹æ”¹å­¦ç”Ÿ {student_name} (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)")
                
                # è°ƒç”¨LLM API
                llm_response = self.call_llm_api(prompt)
                if llm_response is None:
                    raise Exception(f"{self.model_name} APIè°ƒç”¨å¤±è´¥")
                
                # è§£æç»“æœ
                grading_result = self.parse_grading_result(llm_response)
                if grading_result is None:
                    raise Exception("æ‰¹æ”¹ç»“æœè§£æå¤±è´¥")
                
                # æ·»åŠ å…ƒæ•°æ®
                result = {
                    "student_name": student_name,
                    "grading_time": datetime.now().isoformat(),
                    "grading_result": grading_result,
                    "raw_response": llm_response,
                    "model": self.api_config["model"],
                    "retry_count": attempt  # è®°å½•é‡è¯•æ¬¡æ•°
                }
                
                total_score = grading_result.get('æ€»åˆ†', 'N/A')
                if attempt > 0:
                    logger.info(f"âœ… å­¦ç”Ÿ {student_name} æ‰¹æ”¹æˆåŠŸï¼ˆé‡è¯• {attempt} æ¬¡åï¼‰ï¼Œæ€»åˆ†: {total_score}")
                else:
                    logger.info(f"âœ… å­¦ç”Ÿ {student_name} æ‰¹æ”¹å®Œæˆï¼Œæ€»åˆ†: {total_score}")
                return result
                
            except Exception as e:
                if attempt < max_retries - 1:
                    retry_delay = 2 * (attempt + 1)  # é€’å¢å»¶è¿Ÿï¼š2ç§’ã€4ç§’ã€6ç§’
                    logger.warning(f"âš ï¸  å­¦ç”Ÿ {student_name} ç¬¬ {attempt + 1} æ¬¡æ‰¹æ”¹å¤±è´¥: {e}")
                    logger.info(f"ğŸ”„ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                else:
                    logger.error(f"âŒ å­¦ç”Ÿ {student_name} çš„ä½œä¸šæ‰¹æ”¹å½»åº•å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {e}")
                    return None
        
        return None
    
    def grade_all_homeworks(self, homework_dir="../homework3", output_file="deepseek_grading_results.jsonl", max_retries=3):
        """æ‰¹æ”¹æ‰€æœ‰å­¦ç”Ÿçš„ä½œä¸š"""
        homework_path = Path(homework_dir)
        
        if not homework_path.exists():
            logger.error(f"âŒ ä½œä¸šç›®å½•ä¸å­˜åœ¨: {homework_dir}")
            return []
        
        logger.info(f"ğŸ“ å¼€å§‹æ‰¹æ”¹æ‰€æœ‰ä½œä¸šï¼Œä½œä¸šç›®å½•: {homework_path.absolute()}")
        logger.info(f"ğŸ”„ é‡è¯•è®¾ç½®: æ¯ä¸ªå­¦ç”Ÿæœ€å¤šé‡è¯• {max_retries} æ¬¡")
        
        results = []
        total_students = 0
        processed_students = 0
        failed_students = []
        
        # éå†æ‰€æœ‰å­¦ç”Ÿæ–‡ä»¶å¤¹
        for student_dir in homework_path.iterdir():
            if not student_dir.is_dir() or student_dir.name.startswith('.'):
                continue
            
            total_students += 1
            student_name = student_dir.name
            homework_file = student_dir / "homework3.md"
            
            if not homework_file.exists():
                logger.warning(f"âš ï¸  å­¦ç”Ÿ {student_name} æ²¡æœ‰homework3.mdæ–‡ä»¶")
                failed_students.append(f"{student_name} (æ–‡ä»¶ä¸å­˜åœ¨)")
                continue
            
            # æ‰¹æ”¹ä½œä¸šï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            result = self.grade_single_homework(student_name, homework_file, student_dir, max_retries)
            if result:
                results.append(result)
                processed_students += 1
                
                # å®æ—¶ä¿å­˜ç»“æœï¼ˆé˜²æ­¢ä¸­é€”ä¸­æ–­ä¸¢å¤±æ•°æ®ï¼‰
                self.save_results([result], output_file, mode='a')
            else:
                failed_students.append(f"{student_name} (æ‰¹æ”¹å¤±è´¥)")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶ï¼ˆæ³¨æ„ï¼šé‡è¯•æœºåˆ¶å†…éƒ¨å·²æœ‰å»¶è¿Ÿï¼‰
            time.sleep(1)
            
            logger.info(f"ğŸ“Š è¿›åº¦: {processed_students}/{total_students}")
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        logger.info(f"ğŸ‰ æ‰¹æ”¹å®Œæˆï¼æ€»å…±å¤„ç† {processed_students}/{total_students} ä¸ªå­¦ç”Ÿ")
        
        if failed_students:
            logger.warning(f"âš ï¸  å¤±è´¥çš„å­¦ç”Ÿ ({len(failed_students)} ä¸ª):")
            for failed in failed_students:
                logger.warning(f"   - {failed}")
        
        return results
    
    def save_results(self, results, output_file, mode='w'):
        """ä¿å­˜ç»“æœåˆ°JSONLæ–‡ä»¶"""
        try:
            with open(output_file, mode, encoding='utf-8') as f:
                for result in results:
                    f.write(json.dumps(result, ensure_ascii=False) + '\n')
            
            if mode == 'w':
                logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def load_results(self, input_file):
        """ä»JSONLæ–‡ä»¶åŠ è½½ç»“æœ"""
        results = []
        try:
            with open(input_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        results.append(json.loads(line))
            logger.info(f"ä» {input_file} åŠ è½½äº† {len(results)} æ¡ç»“æœ")
            return results
        except Exception as e:
            logger.error(f"åŠ è½½ç»“æœå¤±è´¥: {e}")
            return []
    
    def generate_summary(self, results):
        """ç”Ÿæˆæ‰¹æ”¹ç»Ÿè®¡æ‘˜è¦"""
        if not results:
            return "æ²¡æœ‰æ‰¹æ”¹ç»“æœ"
        
        total_count = len(results)
        scores = []
        
        for result in results:
            grading_result = result.get("grading_result", {})
            total_score = grading_result.get("æ€»åˆ†", 0)
            if isinstance(total_score, (int, float)):
                scores.append(total_score)
        
        if scores:
            avg_score = sum(scores) / len(scores)
            max_score = max(scores)
            min_score = min(scores)
            
            # ç»Ÿè®¡é‡è¯•ä¿¡æ¯
            retry_stats = {}
            for result in results:
                retry_count = result.get("retry_count", 0)
                retry_stats[retry_count] = retry_stats.get(retry_count, 0) + 1
            
            retry_info = "\né‡è¯•ç»Ÿè®¡:"
            for retry_count in sorted(retry_stats.keys()):
                if retry_count == 0:
                    retry_info += f"\n  ä¸€æ¬¡æˆåŠŸ: {retry_stats[retry_count]} äºº"
                else:
                    retry_info += f"\n  é‡è¯•{retry_count}æ¬¡æˆåŠŸ: {retry_stats[retry_count]} äºº"
            
            summary = f"""
{self.model_name}æ‰¹æ”¹ç»Ÿè®¡æ‘˜è¦ï¼š
========================
æ¨¡å‹: {self.api_config.get('model', 'unknown')}
APIåœ°å€: {self.api_config.get('url', 'unknown')}
æ€»æ‰¹æ”¹æ•°é‡: {total_count}
å¹³å‡åˆ†: {avg_score:.2f}
æœ€é«˜åˆ†: {max_score}
æœ€ä½åˆ†: {min_score}
åˆ†æ•°åˆ†å¸ƒ:
  90-100åˆ†: {len([s for s in scores if s >= 90])} äºº
  80-89åˆ†:  {len([s for s in scores if 80 <= s < 90])} äºº
  70-79åˆ†:  {len([s for s in scores if 70 <= s < 80])} äºº
  60-69åˆ†:  {len([s for s in scores if 60 <= s < 70])} äºº
  60åˆ†ä»¥ä¸‹: {len([s for s in scores if s < 60])} äºº{retry_info}
            """
            return summary
        else:
            return "æ— æœ‰æ•ˆåˆ†æ•°æ•°æ®" 