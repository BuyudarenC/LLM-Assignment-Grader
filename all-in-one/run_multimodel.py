#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡å‹ä½œä¸šæ‰¹æ”¹è¿è¡Œè„šæœ¬
æ”¯æŒç”¨æˆ·é€‰æ‹©ä¸åŒçš„æ¨¡å‹è¿›è¡Œæ‰¹æ”¹
"""

from config import MODEL_CONFIGS, DEFAULT_MODEL, HOMEWORK_DIR, OUTPUT_FILE, REQUEST_DELAY
from deepseek_grader import MultiModelGrader
import logging
import sys

# è®¾ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

def show_available_models():
    """æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
    print("ğŸ¤– å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨:")
    print("=" * 60)
    
    for i, (model_key, config) in enumerate(MODEL_CONFIGS.items(), 1):
        status = "âœ…" if config["key"] and config["key"] not in ["", "your-api-key", "sk-local-key-or-empty"] else "âš ï¸"
        print(f"{i}. {model_key}")
        print(f"   åç§°: {config['name']}")
        print(f"   æ¨¡å‹: {config['model']}")
        print(f"   åœ°å€: {config['url']}")
        print(f"   çŠ¶æ€: {status} {'å·²é…ç½®' if status == 'âœ…' else 'éœ€è¦é…ç½®API Key'}")
        print()

def get_user_choice():
    """è·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹"""
    models = list(MODEL_CONFIGS.keys())
    
    while True:
        try:
            choice = input(f"è¯·é€‰æ‹©æ¨¡å‹ (1-{len(models)}) æˆ–ç›´æ¥æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤æ¨¡å‹ [{DEFAULT_MODEL}]: ").strip()
            
            if not choice:
                return DEFAULT_MODEL
            
            choice_num = int(choice)
            if 1 <= choice_num <= len(models):
                return models[choice_num - 1]
            else:
                print(f"âŒ è¯·è¾“å…¥ 1-{len(models)} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            sys.exit(0)

def validate_model_config(model_key):
    """éªŒè¯æ¨¡å‹é…ç½®"""
    config = MODEL_CONFIGS[model_key]
    
    print(f"\nğŸ” éªŒè¯æ¨¡å‹é…ç½®: {config['name']}")
    print("-" * 40)
    
    # æ£€æŸ¥å¿…è¦å­—æ®µ
    required_fields = ["url", "model"]
    for field in required_fields:
        if not config.get(field):
            print(f"âŒ ç¼ºå°‘å¿…è¦é…ç½®: {field}")
            return False
    
    # æ£€æŸ¥API Keyï¼ˆæŸäº›æœ¬åœ°æ¨¡å‹å¯èƒ½ä¸éœ€è¦ï¼‰
    if model_key not in ["local_openai"] and (not config.get("key") or config["key"] in ["", "your-api-key"]):
        print(f"âš ï¸  è­¦å‘Š: {config['name']} çš„API Keyæœªé…ç½®")
        confirm = input("æ˜¯å¦ç»§ç»­? (y/N): ").strip().lower()
        if confirm != 'y':
            return False
    
    print(f"âœ… æ¨¡å‹é…ç½®éªŒè¯é€šè¿‡")
    return True

def test_model_connection(grader):
    """æµ‹è¯•æ¨¡å‹è¿æ¥"""
    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹è¿æ¥...")
    
    test_prompt = """
è¯·å¯¹ä»¥ä¸‹ä½œä¸šå†…å®¹è¿›è¡Œç®€å•è¯„åˆ†æµ‹è¯•ï¼š

# æµ‹è¯•å†…å®¹
è¿™æ˜¯ä¸€ä¸ªè¿æ¥æµ‹è¯•ã€‚

è¯·è¿”å›å¦‚ä¸‹JSONæ ¼å¼ï¼š
{
  "æ€»åˆ†": 85,
  "æµ‹è¯•çŠ¶æ€": "è¿æ¥æˆåŠŸ"
}
    """
    
    try:
        response = grader.call_llm_api(test_prompt)
        if response:
            print("âœ… æ¨¡å‹è¿æ¥æµ‹è¯•æˆåŠŸ")
            print(f"å“åº”ç¤ºä¾‹: {response[:100]}...")
            return True
        else:
            print("âŒ æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥")
            return False
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤šæ¨¡å‹ä½œä¸šæ‰¹æ”¹å™¨")
    print("=" * 60)
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    show_available_models()
    
    # è·å–ç”¨æˆ·é€‰æ‹©
    selected_model = get_user_choice()
    
    # éªŒè¯é…ç½®
    if not validate_model_config(selected_model):
        print("âŒ æ¨¡å‹é…ç½®éªŒè¯å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
        return
    
    config = MODEL_CONFIGS[selected_model]
    print(f"\nğŸ¯ å·²é€‰æ‹©æ¨¡å‹: {config['name']}")
    
    try:
        # åˆå§‹åŒ–æ‰¹æ”¹å™¨
        grader = MultiModelGrader(config, config['name'])
        
        # åŠ è½½æç¤ºè¯
        grader.load_prompt("prompt.txt")
        
        # æµ‹è¯•è¿æ¥ï¼ˆå¯é€‰ï¼‰
        test_connection = input("\næ˜¯å¦æµ‹è¯•æ¨¡å‹è¿æ¥? (Y/n): ").strip().lower()
        if test_connection != 'n':
            if not test_model_connection(grader):
                confirm = input("è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­æ‰¹æ”¹? (y/N): ").strip().lower()
                if confirm != 'y':
                    print("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                    return
        
        # é…ç½®é‡è¯•æ¬¡æ•°
        MAX_RETRIES = 3
        
        # ç¡®è®¤å¼€å§‹æ‰¹æ”¹
        print(f"\nğŸ“‹ æ‰¹æ”¹é…ç½®:")
        print(f"   æ¨¡å‹: {config['name']} ({config['model']})")
        print(f"   ä½œä¸šç›®å½•: {HOMEWORK_DIR}")
        print(f"   è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
        print(f"   é‡è¯•æ¬¡æ•°: {MAX_RETRIES}")
        print(f"   è¯·æ±‚é—´éš”: {REQUEST_DELAY}ç§’")
        
        confirm = input("\nç¡®è®¤å¼€å§‹æ‰¹æ”¹? (Y/n): ").strip().lower()
        if confirm == 'n':
            print("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ¬ å¼€å§‹æ‰¹æ”¹...")
        
        # å¼€å§‹æ‰¹æ”¹
        results = grader.grade_all_homeworks(
            homework_dir=HOMEWORK_DIR,
            output_file=OUTPUT_FILE,
            max_retries=MAX_RETRIES
        )
        
        # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
        if results:
            summary = grader.generate_summary(results)
            print(summary)
            
            # ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶
            summary_file = OUTPUT_FILE.replace('.jsonl', '_summary.txt')
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(summary)
            print(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
        
        print("\nğŸ‰ æ‰¹æ”¹ä»»åŠ¡å®Œæˆï¼")
        
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print("è¯·ç¡®ä¿prompt.txtæ–‡ä»¶å­˜åœ¨äºå½“å‰ç›®å½•")
    
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        print("ğŸ“ å·²æ‰¹æ”¹çš„ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶ä¸­")
    
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        logging.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 